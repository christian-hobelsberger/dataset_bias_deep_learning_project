{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import glob\n",
    "import requests\n",
    "\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading msrc images\n",
    "\n",
    "# Insert path to data folder containing all image datasets\n",
    "filepath = \".../data/\"\n",
    "\n",
    "msrcPath = filepath + \"msrcorid/\"\n",
    "\n",
    "w = os.walk(msrcPath)\n",
    "all_paths = []\n",
    "\n",
    "# create all possible paths\n",
    "for (dirpath, dirnames, filenames) in w:\n",
    "    all_paths.append(dirpath)\n",
    "\n",
    "image_paths = all_paths[:]\n",
    "\n",
    "# delete paths that don't contain a jpg\n",
    "for dirs in all_paths:\n",
    "    if \".JPG\" not in os.listdir(dirs)[0]:\n",
    "        image_paths.remove(dirs)\n",
    "\n",
    "msrc_image_list = []\n",
    "msrc_label_list = []\n",
    "\n",
    "for current_path in image_paths:\n",
    "    \n",
    "    current_jpgpath = current_path + \"/*.jpg\"\n",
    "    \n",
    "    for images in glob.glob(current_jpgpath): \n",
    "        jpg = Image.open(images)\n",
    "        msrc_image_list.append(jpg)\n",
    "        msrc_label_list.append(current_path)\n",
    "\n",
    "\n",
    "# find point up to which all paths have identical names, \n",
    "# so that this can be deleted for the sake of labels. \n",
    "# labels are now based on folder paths\n",
    "isSameChar = False\n",
    "\n",
    "idx = 0\n",
    "while not isSameChar:\n",
    "    char = msrc_label_list[0][idx]\n",
    "    for label in msrc_label_list:\n",
    "        new_char = label[idx]\n",
    "        if new_char != char:\n",
    "            isSameChar = True\n",
    "            cutoff_idx = idx\n",
    "    idx += 1\n",
    "\n",
    "# replace slashes with blank space\n",
    "for label_idx in range(len(msrc_label_list)):\n",
    "    msrc_label_list[label_idx] = msrc_label_list[label_idx][(cutoff_idx):]\n",
    "    msrc_label_list[label_idx] = msrc_label_list[label_idx].replace(\"\\\\\", \" \")\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for downloading images from the labelme website\n",
    "def download_images(url, folder):\n",
    "\n",
    "    # Fetch HTML content of the page\n",
    "    response = requests.get(url)\n",
    "    html_content = response.text\n",
    "\n",
    "    # Use while loop to find all .\"jpg\" hyperlink things in the HTML text thing\n",
    "    index = 0\n",
    "    while True:\n",
    "        index = html_content.find('.jpg', index)\n",
    "        \n",
    "        # The indices are only -1 if no instance of the substring was found (i.e. end of file)\n",
    "        if index == -1:\n",
    "            break\n",
    "            \n",
    "        # Find the start of the image title\n",
    "        start_index = html_content.rfind('\"', 0, index)\n",
    "        if start_index == -1:\n",
    "            break\n",
    "            \n",
    "        # Find the end of image title\n",
    "        end_index = html_content.find('\"', index)\n",
    "        if end_index == -1:\n",
    "            break\n",
    "            \n",
    "        # Get full image url\n",
    "        image_url = url + html_content[start_index + 1:end_index]\n",
    "        \n",
    "        # Download image\n",
    "        image_retrieval = requests.get(image_url)\n",
    "        if image_retrieval.status_code == 200:      # this is a quick safeguard to guarantee that the retrieval was succesfull\n",
    "            # Save the image to folder\n",
    "            filename = os.path.join(folder, os.path.basename(image_url))\n",
    "            \n",
    "            with open(filename, 'wb') as file:\n",
    "                file.write(image_retrieval.content)\n",
    "                \n",
    "        # Update index so that the next jpg can be found\n",
    "        index = end_index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for generating the list of folder urls from the labelme website\n",
    "def find_folders(): \n",
    "    url = \"http://labelme.csail.mit.edu/Images/\"\n",
    "    request = requests.get(url)\n",
    "    html_content = request.text\n",
    "    \n",
    "    folder_list = []\n",
    "\n",
    "    start_index = 0\n",
    "\n",
    "    while start_index != -1:\n",
    "        \n",
    "        # all folder hyperlinks start with the alt=... substring, and end at double quotes.\n",
    "        start_index = html_content.find('alt=\"[DIR]\"></td><td><a href=\"', start_index) + 30\n",
    "        stop_index = html_content.find('\"', start_index)\n",
    "\n",
    "        # quit in case no additional folder was found\n",
    "        if start_index == 29 or stop_index == -1: \n",
    "            break\n",
    "            \n",
    "        folder_url = url + html_content[start_index:stop_index]\n",
    "\n",
    "        folder_list.append(folder_url)\n",
    "        start_index = stop_index + 1\n",
    "\n",
    "    return(folder_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function for getting the associated image labels from the labelme website\n",
    "def obtain_labels(url_folders):\n",
    "\n",
    "    LabelMe_labels = []\n",
    "\n",
    "    for folder_url in url_folders:\n",
    "        \n",
    "        request = requests.get(folder_url)\n",
    "        html_folder_content = request.text\n",
    "        html_length = len(html_folder_content)\n",
    "\n",
    "        index = 0\n",
    "        \n",
    "        # while loop to find the jpg images in the current folder\n",
    "        while True:\n",
    "            index = html_folder_content.find('.jpg', index)\n",
    "      \n",
    "            # break out of while loop if all jpgs have been found\n",
    "            if index == -1:\n",
    "                break\n",
    "            # Find the start of the URL\n",
    "            begin_index = html_folder_content.rfind('\"', 0, index)\n",
    "                            \n",
    "            if begin_index == -1:\n",
    "                break\n",
    "            # Find the end of the URL\n",
    "            end_index = html_folder_content.find('\"', index)\n",
    "            \n",
    "            if end_index == -1:\n",
    "                break\n",
    "            \n",
    "            # obtain image name\n",
    "            image_name = html_folder_content[begin_index:end_index]\n",
    "            \n",
    "            image_url = folder_url + html_folder_content[begin_index + 1:end_index]\n",
    "            \n",
    "            # change url to correct associated annotation url\n",
    "            image_url = image_url.replace(\"Images\", \"Annotations\")\n",
    "            label_url = image_url.replace(\".jpg\", \".xml\")\n",
    "            \n",
    "            start_index = 0\n",
    "            \n",
    "            # initialize the label with the name of the .jpg image (which is used for sorting purposes later)\n",
    "            label = html_folder_content[begin_index + 1:end_index]\n",
    "            \n",
    "            \n",
    "            request = requests.get(label_url)\n",
    "            html_content = request.text\n",
    "\n",
    "        \n",
    "            # Now store all the labels that exist in the annotation part of the jpg\n",
    "            while start_index != -1:\n",
    "                start_index = html_content.find('<name>', start_index) + 6\n",
    "                stop_index = html_content.find('</name>', start_index)\n",
    "\n",
    "                # break out if no more labels are present in the annotation\n",
    "                if start_index == 5 or stop_index == -1:\n",
    "                    break\n",
    "                \n",
    "                # some annotations were added after publication of the unbiasedness paper, \n",
    "                # and they also have a tendency to be wrong, so these labels are not added\n",
    "                forbidden_years = [\"2011\", \"2012\", \"2013\", \"2014\", \"2015\", \"2016\", \"2017\", \"2018\", \"2019\", \"2020\", \"2021\", \"2022\", \"2023\", \"2024\"]\n",
    "\n",
    "                if not any(sub_string in html_content[stop_index:min([stop_index+250, html_length])] for sub_string in forbidden_years):\n",
    "                    label = label + \" \" + html_content[start_index:stop_index]\n",
    "\n",
    "                start_index = stop_index+1\n",
    "\n",
    "            # Add all labels to corresponding annotation\n",
    "            LabelMe_labels.append(label)\n",
    "            \n",
    "            # go to the next jpg in the folder\n",
    "            index = end_index + 50\n",
    "    return(LabelMe_labels)\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download images from labelme website\n",
    "\n",
    "# retrieve all folder urls which have the images\n",
    "url_folders = find_folders()\n",
    "\n",
    "# uncomment next line for testing (here only images in the first 3 folders are downloaded)\n",
    "url_folders = url_folders[0:3]   \n",
    "\n",
    "# Specify correct path to label me folder\n",
    "folder_to_store_images = \".../data/LabelMe\"\n",
    "\n",
    "# Download the images (WARNING: might take a while for the full image set)\n",
    "for url in url_folders:\n",
    "    download_images(url, folder_to_store_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading labelme images\n",
    "\n",
    "# Retrieve labels from website + load images from locally stored labelme folder\n",
    "\n",
    "labelMe_label_list = obtain_labels(url_folders)\n",
    "\n",
    "labelMe_image_list = []\n",
    "\n",
    "# Specify correct path to label me folder\n",
    "current_path = \".../data/LabelMe\"\n",
    "\n",
    "current_jpgpath = current_path + \"/*.jpg\"\n",
    "\n",
    "for images in glob.glob(current_jpgpath): \n",
    "    jpg = Image.open(images)\n",
    "    labelMe_image_list.append(jpg)\n",
    "\n",
    "# sort label list alphabetically. \n",
    "# This is done because the images were pulled from the local data folder in order. \n",
    "# Since (Windows at least) automatically orders all images in the folder automatically, \n",
    "# we also have to sort the label list so that the indices align with the corresponding image\n",
    "labelMe_label_list = sorted(labelMe_label_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading caltech images\n",
    "\n",
    "# Insert path to data folder containing all image datasets\n",
    "filepath = \".../data/\"\n",
    "\n",
    "filepath = \"C:/Users/Gebruiker/Documents/aaStudie23-24/aDeepLearning/Project 2/data/\"\n",
    "\n",
    "\n",
    "caltech_path = filepath + \"caltech-101/\"\n",
    "\n",
    "w = os.walk(caltech_path)\n",
    "all_paths = []\n",
    "\n",
    "\n",
    "for (dirpath, dirnames, filenames) in w:\n",
    "    all_paths.append(dirpath)\n",
    "\n",
    "\n",
    "image_paths = all_paths[:]\n",
    "\n",
    "for dirs in all_paths:\n",
    "    if \".JPG\" not in os.listdir(dirs)[0]:\n",
    "        image_paths.remove(dirs)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "caltech_image_list = []\n",
    "caltech_label_list = []\n",
    "\n",
    "for current_path in image_paths:\n",
    "    \n",
    "    current_jpgpath = current_path + \"/*.jpg\"\n",
    "    \n",
    "    for images in glob.glob(current_jpgpath): \n",
    "        jpg = Image.open(images)\n",
    "        caltech_image_list.append(jpg)\n",
    "        caltech_label_list.append(current_path)\n",
    "\n",
    "\n",
    "isSameChar = False\n",
    "\n",
    "idx = 0\n",
    "while not isSameChar:\n",
    "    char = caltech_label_list[0][idx]\n",
    "    for label in caltech_label_list:\n",
    "        new_char = label[idx]\n",
    "        if new_char != char:\n",
    "            isSameChar = True\n",
    "            cutoff_idx = idx\n",
    "    idx += 1\n",
    "\n",
    "\n",
    "for label_idx in range(len(caltech_label_list)):\n",
    "    caltech_label_list[label_idx] = caltech_label_list[label_idx][(cutoff_idx):]\n",
    "    caltech_label_list[label_idx] = caltech_label_list[label_idx].replace(\"\\\\\", \" \")\n",
    "\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
